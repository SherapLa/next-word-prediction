{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W-rV8PFK_Y6x"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s2XIAghN7P2T"
   },
   "source": [
    "# Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vKkp55Gp7O3w"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-20 00:09:29.508352: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-04-20 00:09:29.521560: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 3s 0us/step\n"
     ]
    }
   ],
   "source": [
    "num_classes = 2\n",
    "model = Sequential()\n",
    "model.add(ResNet50(include_top=False, pooling='avg', weights='imagenet'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# not using the first layer for training\n",
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m5A52wNc7UPm"
   },
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "On1zsbm9AEtA"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', \n",
    "                     loss='categorical_crossentropy', \n",
    "                     metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wLgrkDwp7hHr"
   },
   "source": [
    "# Image augmentation for preprocessing image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v6d3tF3OMzHL"
   },
   "outputs": [],
   "source": [
    "data_generator_with_aug = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
    "                                              horizontal_flip = True, \n",
    "                                              width_shift_range = 0.1,\n",
    "                                              height_shift_range = 0.1)\n",
    "            \n",
    "data_generator_no_aug = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xP9TPIKL8KrE"
   },
   "source": [
    "# Take image directly from director and apply augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "Xd15VDFhDe3O",
    "outputId": "69dcdfb1-1a77-4869-d5e1-7cd4e19e3d43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 images belonging to 2 classes.\n",
      "Found 36 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "image_size = 224\n",
    "\n",
    "train_generator = data_generator_with_aug.flow_from_directory(\n",
    "                                        directory='/Users/sherapgyaltsen/Documents/Face-mask-detection/train',\n",
    "                                        classes = ['with_mask', 'without_mask'],\n",
    "                                        target_size=(image_size, image_size),\n",
    "                                        batch_size=10,\n",
    "                                        class_mode='categorical')\n",
    "validation_generator = data_generator_no_aug.flow_from_directory(\n",
    "                                        directory='/Users/sherapgyaltsen/Documents/Face-mask-detection/val',\n",
    "                                        classes = ['with_mask', 'without_mask'],\n",
    "                                        target_size=(image_size, image_size),\n",
    "                                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "egyQU56K8XOa"
   },
   "source": [
    "# Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "TDY-C13s8Zva",
    "outputId": "01160775-a467-4644-9d9a-de3026895d1f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sherapgyaltsen/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 4/60 [=>............................] - ETA: 45s - loss: 0.3105 - accuracy: 0.8611WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 600 batches). You may need to use the repeat() function when building your dataset.\n",
      "60/60 [==============================] - 9s 121ms/step - loss: 0.3105 - accuracy: 0.8611 - val_loss: 0.0034 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "fit_stats = model.fit_generator(train_generator,\n",
    "                                       steps_per_epoch=60,\n",
    "                                       epochs = 10,\n",
    "                                       validation_data=validation_generator,\n",
    "                                       validation_steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W5ofqSpT8l2R"
   },
   "source": [
    "# Testing with test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "GSYPzqrwHVBk",
    "outputId": "3c8164a5-9a02-4bb3-83cf-28735e825905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sherapgyaltsen/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 459ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator = data_generator_no_aug.flow_from_directory(\n",
    "    directory='/Users/sherapgyaltsen/Documents/Face-mask-detection/test',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size= 10,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "pred=model.predict_generator(test_generator, steps=len(test_generator), verbose=1)\n",
    "cl = np.round(pred)\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "\n",
    "\n",
    "real_class = []\n",
    "for file in filenames:\n",
    "  if re.search(\"with_mask\", file):\n",
    "    real_class.append(1.0)\n",
    "  else:\n",
    "    real_class.append(0.0)\n",
    "\n",
    "predicted_class = cl[:,0]\n",
    "\n",
    "results=pd.DataFrame({\"file\":filenames,\"pr\":pred[:,0], \"pred_class\":predicted_class, \"real_class\":real_class})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "colab_type": "code",
    "id": "b68ts5VmbCpR",
    "outputId": "cab36572-c705-4327-cad9-8ec60544fd2c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>pr</th>\n",
       "      <th>pred_class</th>\n",
       "      <th>real_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>with_mask/opencv_frame_0.png</td>\n",
       "      <td>0.991802</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>with_mask/opencv_frame_1.png</td>\n",
       "      <td>0.998883</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>with_mask/opencv_frame_2.png</td>\n",
       "      <td>0.999575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>with_mask/opencv_frame_3.png</td>\n",
       "      <td>0.999243</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>with_mask/opencv_frame_4.png</td>\n",
       "      <td>0.999897</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>with_mask/opencv_frame_5.png</td>\n",
       "      <td>0.999828</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>with_mask/opencv_frame_6.png</td>\n",
       "      <td>0.999850</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>without_mask/img1.png</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>without_mask/img2.png</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>without_mask/img3.png</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>without_mask/img4.png</td>\n",
       "      <td>0.015837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>without_mask/img5.png</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>without_mask/img6.png</td>\n",
       "      <td>0.009970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>without_mask/img7.png</td>\n",
       "      <td>0.004970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            file        pr  pred_class  real_class\n",
       "0   with_mask/opencv_frame_0.png  0.991802         1.0         1.0\n",
       "1   with_mask/opencv_frame_1.png  0.998883         1.0         1.0\n",
       "2   with_mask/opencv_frame_2.png  0.999575         1.0         1.0\n",
       "3   with_mask/opencv_frame_3.png  0.999243         1.0         1.0\n",
       "4   with_mask/opencv_frame_4.png  0.999897         1.0         1.0\n",
       "5   with_mask/opencv_frame_5.png  0.999828         1.0         1.0\n",
       "6   with_mask/opencv_frame_6.png  0.999850         1.0         1.0\n",
       "7          without_mask/img1.png  0.001084         0.0         0.0\n",
       "8          without_mask/img2.png  0.002584         0.0         0.0\n",
       "9          without_mask/img3.png  0.004708         0.0         0.0\n",
       "10         without_mask/img4.png  0.015837         0.0         0.0\n",
       "11         without_mask/img5.png  0.004785         0.0         0.0\n",
       "12         without_mask/img6.png  0.009970         0.0         0.0\n",
       "13         without_mask/img7.png  0.004970         0.0         0.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8R4_Xs5a21iH",
    "outputId": "cd2f00a0-aaca-464c-e53d-438765922602"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "res = sum(1 for x,y in zip(real_class,predicted_class) if x == y) / len(real_class)\n",
    "print(\"Accuracy :\", res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R5YCEhnBiT6e"
   },
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GaKfpVijhX7i"
   },
   "outputs": [],
   "source": [
    "model.save('maskDetectionModel_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMFi/BeB7ZWbpTuyutRO8AE",
   "include_colab_link": true,
   "name": "maskDetection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
